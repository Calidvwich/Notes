# 1. 操作系统概述
## 1. 操作系统
一组主管和控制计算机操作，运用和运行硬件，软件资源和提供公共服务来组织用户交互的相互关联的系统软件程序。
	作用：管理/配置内存；决定资源使用的先后顺序，控制输入输出设备，操作系统和管理文件系统等，也是用户和系统交互的页面
## 2. 特征
1. 并发：两个/多个活动在同一给定的时间间隔中进行
2. 共享：计算机系统中的资源被多个进程公用
3. 异步：进程以不可预知的速度向前推及
4. 虚拟：把一个物理上的实体对应为多个逻辑上的对应物
最基本的特征是并发和共享，二者互为存在条件
## 3. 并发VS并行：
同一时间间隔是并发，同一时刻是并行
## 4. 虚拟
将计算机的实体资源抽象转化后呈现的一个可供分割，组合的一个/多个电脑配置环境。可以打破实体之间的阻碍，能够更好更高效地利用资源。
## 5. 功能：
1. 处理机管理：主要功能包括进程控制，进程同步，进程通信，死锁处理，处理机调度等
2. 存储器管理：包括内存分配，地址映射，内存保护与共享，内存扩充等
3. 文件管理：包括文件存储空间管理，目录管理，文件读写管理和保护等
4. 设备管理：缓冲管理，设备分配，设备处理，虚拟设备等
## 6.  用户接口
发展历程：
	1. 手工操作阶段：人机系统速度矛盾
	2. 单道批处理阶段：缓解人机系统速度矛盾，系统资源利用率仍然低
	3. 多道批处理阶段：资源利用率高，但是交互性不足
		1. 分时操作系统：不允许插队，有人机交互，但是不能优先处理紧急事务
		2. 实时操作系统：允许插队，能够优先处理紧急事务，包含硬实时系统（必须在被控制对象规定时间内完成）和软实时系统（可以略松一些，比如购票系统）
		从可靠性看，实时操作系统更强；从交互性看，分时操作系统更强
 基本概念：
	4. 特权指令：不允许用户使用，比如IO指令，中断指令
	5. 非特权指令：普通的运算指令，允许用户使用
	6. 内核程序：系统的管理者，可以执行一切指令，运行在核心态
	7. 应用程序：普通用户程序只能执行非特权指令，运行在用户态
	8. 处理机状态：用户态/目态，核心态/管态/内核态
	9. 用户态到核心态：中断
	10. 核心态到用户态：依靠特权指令psw的标志位，0是用户态，1是核心态
## 7.  原语
处在操作系统最底层的程序，是最接近硬件的部分；运行具有原子性，操作不可中断；程序运行时间较短，调用较为频繁
## 8. 中断
包含内中断（异常，信号来自内部，分为自愿中断/指令终端，和强迫中断/硬件or软件中断）和外中断（中断，信号来自外部，一般包括外设请求和人工干预等）
中断是系统调用系统给程序员/程序的唯一接口，可以获得OS的服务并进入内核态处理
## 9. 体系结构
包含大内核，微内核
![[Pasted image 20250131192913.png]]

# 2. 进程管理
## 1. 进程：
计算机中的程序关于某个数据集合进行的一次运行活动，是系统进行资源分配的基本单位和操作系统结构的基础。在早期操作系统中，进程曾经是程序的基本执行实体；对于多数现代操作系统而言，由于多是面向进程设计，因此成为了线程的容器，不再是基本执行实体。
进程是对正在运行程序过程的一个抽象，同时客观上是一种能够描述动态系统的内在规律的数据结构，能够管理调度进入主存储器的程序
特点：
	1. 并发性：任何进程都可以和其他进程并发执行
	2. 动态性：程序在多道程序系统中的一次执行过程，动态产生动态消亡
	3. 独立性：是一个能够独立运行的基本单位，也是系统分配和调度资源的基本单位
	4. 异步性：进程具有间断性，按照各自独立的不可预知的速度向前推进
结构特征：
	1. PCB（进程控制）：保存进程运行期间的相关数据，是进程存在的唯一标志
	2. 程序段：能被进程调用到CPU的代码
	3. 数据段：存放数据
进程的状态：
	1. 运行态：进程正在占用CPU
	2. 就绪态：进程处于准备运行的状态，获得了除了处理机外的所有资源
	3. 阻塞态：进程由于等待某一时间不能使用CPU
	4. 创建态：进程正在被创建
	5. 结束态：进程正在从系统消失
各个阶段的切换满足如下：![[Pasted image 20250201140352.png]]
## 2. 线程
当下操作系统能够运算调度的最小单位，包含在进程中，是进程中实际运行的最小单位。
一个进程可以并发多个线程，线程可以执行不同的任务
## 3. 处理机调度
分类：
	1. 高级调度（作业调度）
	2. 中级调度（内存置换）
	3. 低级调度（进程调度）
调度方式：剥夺式，非剥夺式
调度准则：CPU利用率，系统吞吐量，周转时间，等待时间，响应时间
3. 算法：
	1. FCFS/先来先服务：用户作业和就绪进程按提交顺序或变为就绪状态的顺序先后拍成队列，基于此来进行服务的调度管理
	2. SJF/短任务优先：优先调度运行时间最短的作业
	3. 优先级调度算法：优先级高的先调度
	4. HRN/高相应比优先调度算法时间片轮转：FCFS和SJF的综合，基于平衡相应比R来排序，R定义为系统对作业响应时间和作业要求运行时间的比值
	5. 多级反馈队列调度算法：如下图
	![[Pasted image 20250201165604.png]]
	
## 4. 进程同步
原因：协调进程之间的相互制约关系
制约关系：为了完成某个任务而建立的多个线程之间，在某些位置上协调工作顺序而产生的等待，传递信息的关系；
互斥/间接制约关系：当一个进程进入临界区使用临界资源时另一个进程必须等待；只有前者进程退出临界区后才能访问临界资源
临界资源：一次仅允许一个进程使用的资源
临界区：在每个进程中能访问临界资源的代码段；由于在多线程并发执行的情况下，所有进程都能访问某些数据会导致数据错误，因此临界区会限制同时执行该段代码的数量保证访问共享资源的时候是互斥的![[Pasted image 20250201173948.png]]
并发的异步特性可以用下图解释
![[Pasted image 20250201174100.png]]
## 5. 临界区的作用和实现
作用：
	- 保护共享资源：确保在任意时刻只有一个进程可以访问/修改共享资源，实现资源的完整性和一体性的保障
	- 防止竞态条件：临界区通过确保只有一个线程在任意时刻执行，避免竞态条件的发生
	- 竞态条件：多个线程同时访问共享资源时，由于执行顺序的不确定性导致结果不可预测的状况
	-  提高程序稳定性：合理设置临界区可以减少并发程序中的错误和异常
临界区的实现一般依靠同步机制，包含以下三种：
	1. 互斥锁mutex：一个进入临界区的线程会获得mutex，退出临界区时释放mutex；其他线程试图进入临界区的时候，如果mutex已经被占用，那么会被阻塞，直到mutex被释放
	2. 信号量：更常用，可以通过在临界区设置为1模拟mutex
	3. 条件变量：一般和mutex一起使用，用于在多个线程之间传递信号，提供线程等待进入临界区的等待和唤醒机制
## 6. 临界区互斥
原则：
	1. 空闲让进:如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入
	2. 忙则等待:任何时候，处于临界区内的进程不可多于一个。
	3. 有限等待:进入临界区的进程要在有限时间内退出，以便其它进程能及时进入自己的临界区。
	4. 让权等待:如果进程不能进入自己的进程/线程，则应让出CPU避免进程出现“忙等”现象。
基本方法：信号量+pv操作实现互斥
用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作，从而很方便的实现了进程互斥、进程同步。一般而言，信号量是系统提供的协调共享资源的方法，表示资源的数量，变量是一个整型（sem）。
P操作：sem-1，若$sem<0$，进入阻塞等待，否则继续，用在进入临界区之前
V操作：sem+1，若sem$\le0$，唤醒一个等待中的线程，用在离开临界区之后
PV操作必须成对出现![[Pasted image 20250201185539.png]]
原语是一种特殊的程序段，由开/关中断指令实现，必须一次执行完
## 7. 死锁
定义：多个进程因竞争资源造成的僵局，如果没有外力无法解决
原因：非剥夺资源的竞争，进程的不恰当推进顺序
一般而言，同时满足以下四个条件就会造成死锁：
	1. 互斥条件：至少有一个资源处于非共享模式，也就是某个资源一次只能被一个进程使用，如果另一进程申请该资源，那么申请进程应等到该资源被释放之后才能使用。
	2. 不可剥夺条件：进程所占有的资源在未使用完毕之前，不能被其他进程强行夺走，只能由占有该资源的进程主动释放
	3. 请求与保持条件：进程已经占有了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。
	4. 循环等待条件：存在一种进程资源的循环等待链，链中每一个进程已占有的资源同时被链中下一个进程所请求。
解决方法：
	1. 预防死锁：
		1. 破坏互斥条件
		2. 破坏不剥夺条件
		3. 破坏请求和保持条件
		4. 破坏循环等待条件
	2. 避免死锁：安全状态，银行家算法
	3. 检测死锁：利用死锁定理
	4. 解除死锁：
		1. 资源剥夺法：强行挂起或撤销某些进程，释放这些进程占有的资源
		2. 撤销进程法：按照某种策略撤销死锁进程，直到解除死锁。
		3. 进程回退法：让某些进程回退到能够避免死锁的地步，释放被占有的资源，这种方法也增加了实现的难度和复杂度，要求保留执行的历史信息并设置还原点。
银行家算法：![[Pasted image 20250201190604.png]]
相比发生死锁之后解除死锁，更重要的还是死锁的预防和避免，常见的避免死锁的方式有：
	1、限制加锁的顺序，也就是说不同进程按照相同的顺序加锁
	2、设置锁的超时时间，给每个锁加一个超时时间，超过这个时间必须释放锁（例如：基于数据库的分布式锁）
	3、死锁检测，在既无法限制加锁顺序也不能限制锁的占有时间情况下，还有一种避免死锁的方式，就是进行死锁检测，系统对进程发出的资源申请进行动态检查，并根据检查结果决定是否分配资源，如果分配后系统可能发生死锁，则不予分配，否则予以分配，这是一种保证系统不进入死锁状态的动态策略。（常用于关系性数据库的死锁避免方式）

# 3. 内存管理
## 1.  目的和功能
目的：更好支持多道程序的并发执行，提高性能
功能：
	1. 内存空间的分配和回收
	2. 存储的保护和共享：保证各个作业在各个空间内运行
	3. 地址转换：逻辑地址转换为对应的物理地址
	4. 内存扩充：从逻辑上扩充内存（虚拟存储，自动覆盖等）
## 2. 用户程序的主要处理阶段 
1. 编辑阶段：创建源文件
2. 编译阶段：编译程序将用户源代码编译成若干目标模块，生成若干目标文件
3. 链接阶段：将编译完成后的一组目标模块和需要的库函数连接在一起，形成一个完整的装入模块，生成可执行文件
4. 装入阶段：由装入程序将装入模块装入内存运行
5. 运行阶段：得到结果
## 3. 程序的装入
程序的装入包含以下几种装入方式：
1. 绝对装入
	定义：在编译时如果知道程序将驻留在内存的什么位置，那么编译程序将产生绝对地址的目标代码（按照物理内存的位置赋予实际的物理地址）
	优点：时间效率高
	缺点：受内存大小限制，能够装入内存并发执行的进程数减少；编译程序必须知道内存当前的空闲地址部分和其地址，在多通道程序下并不可能，因此只适用于单通道环境
2. 静态重定位
	定义：在程序装入对目标代码装入内存的过程中完成。在程序开始运行前，程序中指令和数据的地址已经完成重定位。地址变换通常在装入时一次完成，此后不再改变
	优点：不需要硬件（重定位寄存器）支持
	缺点：程序的存储空间必须是连续的；重定位完成后无法修改
3. 动态重定位
	定义：把地址转换推迟到程序要真正执行的时候才进行
	优点：可以解决碎片问题，每个模块之间的存储不一定要相连
	缺点：必须依靠硬件（重定位寄存器）支持
## 4. 程序的链接
程序的链接包含以下几种链接方式：
1. 静态链接：在程序运行之前，先将各个目标模块以及他们所需的库函数链接成一个完整的可执行程序，此后不再拆开
2. 装入时链接：将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的连接方式
3. 运行时链接：对某些目标模块的链接在程序执行时需要的时候才链接。便于共享，修改和更新
## 5. 地址空间
包含逻辑地址空间和物理地址空间
内存空间的分配和回收包含以下方式
	1. 连续分配管理方式：
		1. 单一连续分配：分配到内存固定的区域（单用户/单任务的操作系统）
		2. 固定分区分配：分配到内存不同的固定区域，分区大小可以不等但是要固定
		3. 动态分区分配：
			1. 可变分区的存储管理：按照程序需要进行动态划分
			2. 动态分区的分配策略算法：
				1. 首次适应：空闲区域以地址递增的次序链接，分配内存时按照顺序查找，找到大小能够满足要求的一个空闲分区
				2. 最佳适应：空闲分区按照容量递增的顺序形成分区链，找到第一个满足的
				3. 最坏适应：空闲分区按照容量递减的顺序形成分区链，找到第一个满足的（最大的）
				4. 临近适应：由1修改而来，分配内存时改为从上次结束的位置开始继续查找
	2. 非连续分配管理方式：
		优势：解决上述方法中必须连续带来的碎片化问题
		1. 基本分页式存储管理：将内存空间分为一个个大小相等的分区，每个分区叫做一个页框/页帧/内存块/物理块，且有唯一从0开始的编号页框号。将用户进程的地址空间也分为和页框大小相同的区域，称为“页”。同样的每个页也有一个唯一从0开始的编号“页号”。操作系统以页框为单位为进程分配空间，每个页面进入一个页框，页面不一定要连续存放。
	![[Pasted image 20250202181633.png]]![[Pasted image 20250202181712.png]]
		2. 基本分段式存储管理：作业的地址空间被划分为了若干个段，每个段定义一个逻辑信息，其余和分页式原理相同。因为各段大小不同，因此段中一定要存储段长度。
		![[Pasted image 20250202182309.png]]![[Pasted image 20250202182414.png]]
		3. 段页式存储管理：将前二者结合
页是信息的物理单位。分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可见的。段是信息的逻辑单位。分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显式地给出段名。页的大小固定且由系统决定。段的长度却不固定，决定于用户编写的程序。分页的用户进程地址空间是一维的，程序员只需给出一个记忆符即可表示一个地址。分段的用户进程地址空间是二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址。

分页一般而言不会产生外部碎片，仅会有少量页内碎片，但是不便于按照逻辑模块实现信息的共享和保护；分块则相反，虽然便于按照逻辑模块实现信息的共享和保护，但是段长过大不利于分配连续空间，并且容易产生外部碎片
## 6. 快表
TLB，用来存放最近访问的页表项的副本，加速地址变换速度（减少访存次数）
![[Pasted image 20250202181905.png]]![[Pasted image 20250202182002.png]]TLB和普通cache的区别在于，TLB只有页表项的副本，cache不仅限于此
## 7. 内存扩充
1. 覆盖：将程序分为多个段，常用的常驻内存，不常用的只有在需要的时候再调入内存
2. 交换：内存空间紧张的时候，系统将内存中的某些进程暂时换出外存，把外存中一些具有运行条件的换入内存，实现进程在磁盘和内存之间的动态调度
3. 虚拟内存：
	1. 引入原因：在逻辑上实现内存扩充
	2. 组成部分：页表机制，中断机制，地址变换机制，内存和外存
	3. 置换算法：
		1. FIFO（先进先出）：淘汰最先进入内存的页面
		2. LRU（最近最久未使用）：把最长时间未访问过的淘汰
		3. clock（最近最少用）：把当前使用最少的页面淘汰
		4. OPT（最优淘汰）：把以后不再使用的/最长时间内不再使用的淘汰，实际上难实现
		注意页面淘汰由缺页中断引起，但是缺页中断不一定会引起页面淘汰
	4. 整体流程：CPU需要取地址，首先访问页表(页表包含页号和块号两部分)如果在页表中找到了，那么利用地址变换机制，变成真正的物理地址，计算机通过寻找该物理地址找到自己需要的资源。如果发现页表没有自己想要的页表项，那么会触发缺页中断(缺页中断就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。)从外存调入内存的过程，如果页表满了，需要从满了的页表项中进行替换。
	![[Pasted image 20250202184745.png]]
	